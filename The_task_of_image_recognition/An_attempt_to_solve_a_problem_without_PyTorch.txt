"""
# padding function
def get_padding2d(input_images, padding):

    batch_size, channels, height, width = input_images.shape

    padded_height = height + 2 * padding

    padded_width = width + 2 * padding

    padded_images = torch.zeros((batch_size, channels, padded_height, padded_width),
         dtype=input_images.dtype)

    padded_images[:, :, padding:padding + height, padding:padding + width] \
        = input_images

    return padded_images

# conv function
def convolution2d_manual(input_images, kernel, stride):

    batch_size, in_channels, input_height, input_width = input_images.shape
    out_channels, kernel_in_channels, kernel_height, kernel_width = kernel.shape

    output_height = (input_height - kernel_height) // stride + 1
    output_width = (input_width - kernel_width) // stride + 1

    output_images = torch.zeros((batch_size, out_channels, output_height, output_width), dtype=input_images.dtype)

    for b in range(batch_size):
        for oc in range(out_channels):
            for oh in range(output_height):
                for ow in range(output_width):

                    start_h = oh * stride
                    end_h = start_h + kernel_height
                    start_w = ow * stride
                    end_w = start_w + kernel_width

                    input_window = input_images[b, :, start_h:end_h, start_w:end_w] # shape (in_channels, 7, 7)

                    current_kernel = kernel[oc, :, :, :] # shape (in_channels, 7, 7)

                    output_value = torch.sum(input_window * current_kernel)
                    output_images[b, oc, oh, ow] = output_value

    return output_images
"""

------------------------------------------------------------------------------------------------------------------------
